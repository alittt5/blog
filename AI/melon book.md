# 西瓜书
## 2. 模型评估和选择
### 2.1 误差
### 2.2 过拟合、欠拟合

### 2.3 数据集划分

训练集用来计算梯度更新权重，即训练模型；  
验证集用来做模型选择，而且可以避免过拟合。在训练过程中，我们通常用它来确定一些超参数。（例：根据验证集的准确率来确定early stoping的epoch大小，根据验证集确定学习率等等）  
测试集则给出一个准确率以判断网络性能的好坏。


![[Pasted image 20221013172536.png]]

**数据集划分方法**

1.留出法（Hold-out）
为了保证数据分布的一致性，通常我们采用分层采样的方式来对数据进行采样。

1.如果数据比较少：
只划分训练集和测试集则为：70%验证集，30%测试集；
划分训练集、验证集和测试集则为：60%训练集，20%验证集，20%测试集。
2.数据比较多：
只需要取一小部分当做测试集和验证集，其他的都当做训练集。

然后使用训练集来生成模型，验证集来选择模型，最后用测试集来测试模型的正确率和误差，以验证模型的有效性。

这种方法常见于决策树、朴素贝叶斯分类器、线性回归和逻辑回归等任务中。

缺点：只进行了一次划分，数据结果具有偶然。

2.交叉验证法（Cross Validation）
为了保证数据分布的一致性，这里我们依然采用分层采样的方式来对数据进行采样。

交叉验证一般采用k kk折交叉验证，往往k kk取为10。
具体步骤：
交叉验证是将一个整体数据平均划分为K份
先取第一份子集数据作为测试集，剩下的K-1份子集数据作为训练集
再取第二份子集数据作为测试集，剩下的K-1份子集数据作为训练集
…
不断往复，重复K次
然后将得到的结果进行加权平均，作为最终的评估结果

为了保证数据分布的一致性，通常我们采用分层采样的方式来对数据进行采样。

优点：降低由一次随机划分带来的偶然性，提高其泛化能力，提高对数据的使用效率。

缺点：可能存在一种情况：数据集有5类，抽取出来的也正好是按照类别划分的5类。这样的结果就会导致，模型训练时没有学习到测试集中数据的特点，从而导致模型得分很低，甚至为0，

特例：
当 k=1的时候，我们称之为留一法
我们令样本划分次数K等于数据集合D的样本数量n，即把样本集合D划分为n份子集。
可以发现，留一法并不需要多次划分，其划分方式只有一种。

优点：因为留一法中的 S 与 D 很接近，所以 S 所训练出来的模型应该与 D 所训练出来的模型很接近，因此通常留一法得到的结果是比较准确的

缺点：当数据集很大的时候，留一法的运算成本将会非常的高以至于无法忍受。

3.自助法（BootStrapping）
留出法与交叉验证法都是使用分层采样的方式进行数据采样与划分，而自助法则是使用有放回重复采样的方式进行数据采样。

我们每次从数据集D中取一个样本作为训练集中的元素，然后把该样本放回，重复该行为 m 次，这样我们就可以得到大小为m的训练集，在这里面有的样本重复出现，有的样本则没有出现过，我们把那些没有出现过的样本作为测试集，剩余的作为训练集。

对任意一个样本，在m次采样中没有被取到的概率为$(1-\frac{1}{m})^{m}$
 
取极限为 $\frac{1}{e} \approx$ 0.368 

优点：自助法在数据集较小、难以有效划分训练集和测试集时很有用。此外，自助法能从初始数据集中产生多个不同的训练集，这对集成学习等方法有很大的好处。

缺点：自助法产生的数据集改变了初始数据集的分布，这会引入估计偏差。因此在初始数据量足够时，留出法和交叉验证法更加常用一些

**划分方法的选择**

对于数据量充足的时候，通常采用留出法或者k折交叉验证法来进行训练/测试集的划分；

对于数据集小且难以有效划分训练/测试集时使用自助法；

对于数据集小且可有效划分的时候最好使用留一法来进行划分，因为这种方法最为准确 。

### 2.4 性能指标

#### 2.4.1 错误率和精度

错误率 
$$E(f ; D)=\frac{1}{m} \sum_{i=1}^m \mathbb{I}\left(f\left(\boldsymbol{x}_i\right) \neq y_i\right)$$
准确率
$$
\begin{aligned}
\operatorname{acc}(f ; D) &=\frac{1}{m} \sum_{i=1}^m \mathbb{I}\left(f\left(\boldsymbol{x}_i\right)=y_i\right) \\
&=1-E(f ; D) .
\end{aligned}
$$
#### 2.4.2 查准率、查全率、F1

查准率为预测结果为正例中实际正例的占比  
查全率为真实情况为正例中预测正例的占比



混淆矩阵 
$$
\begin{array}{c|c|c}
\hline {\text { 真实情况 }} & \\
 & \text { 正例 } & \text { 反例 } \\
\hline \text { 正例 } & T P \text { (真正例) } & F N \text { (假反例) } \\
\hline \text { 反例 } & F P \text { (假正例) } & T N \text { (真反例) } \\
\hline
\end{array}
$$

查准率 :“挑出的西瓜有多少是好西瓜”
$$
P=\frac{T P}{T P+F P}
$$
查全率 :“所有好瓜中有多少被挑了出来”
$$
R=\frac{T P}{T P+F N}
$$
查准率和查全率是一对矛盾的度量.一般来说，查准率高时，查全率往往偏低;而查全率高时，查准率往往偏低.例如，若希望将好瓜尽可能多地选出来， 则可通过增加选瓜的数量来实现，如果将所有西瓜都选上，那么所有的好瓜也必然都被选上了，但这样查准率就会较低;若希望选的瓜中好瓜比例尽可能 高，则可只挑选最有把握的瓜 但这样就难免会漏掉不少好瓜，使得查全率较低.通常只有在一些简单任务中才可能使查全率和查准率都很高.
![[~D$W32OC(0NRAVZU}[UP0`4.png]]

F1 
$$
F 1=\frac{2 \times P \times R}{P+R}=\frac{2 \times T P}{\text { 样例总数 }+T P-T N}
$$
#### 2.4.3 ROC、AUC

ROC 曲线则是从这个角度出发来研究学习器泛化性能的有力工具.
ROC 曲线的纵轴是"真正 例率" (True Positive Rate ，简称 TPR) ，横轴是"假正例率" (False Positive Rate ，简称 FPR)